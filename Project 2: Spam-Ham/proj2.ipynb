{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Spam/Ham Classification\n",
    "## Feature Engineering, Logistic Regression, Cross Validation\n",
    "## Due Date: Monday 11/30, 11:59 PM PST\n",
    "\n",
    "**Collaboration Policy**\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about\n",
    "the project, we ask that you **write your solutions individually**. If you do\n",
    "discuss the assignments with others please **include their names** at the top\n",
    "of your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators**: *list collaborators here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "proj2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## This Assignment\n",
    "In this project, you will use what you've learned in class to create a classifier that can distinguish spam (junk or commercial or bulk) emails from ham (non-spam) emails. In addition to providing some skeleton code to fill in, we will evaluate your work based on your model's accuracy and your written responses in this notebook.\n",
    "\n",
    "After this project, you should feel comfortable with the following:\n",
    "\n",
    "- Feature engineering with text data\n",
    "- Using `sklearn` libraries to process data and fit models\n",
    "- Validating the performance of your model and minimizing overfitting\n",
    "- Generating and analyzing precision-recall curves\n",
    "\n",
    "## Warning\n",
    "This is a **real world** dataset– the emails you are trying to classify are actual spam and legitimate emails. As a result, some of the spam emails may be in poor taste or be considered inappropriate. We think the benefit of working with realistic data outweighs these innapropriate emails, and wanted to give a warning at the beginning of the project so that you are made aware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer about `sns.distplot()`\n",
    "\n",
    "This project was designed for a slightly older version of seaborn, which does not support the new `displot` method taught in Lecture 9. Instead, in this project will occasionally call `distplot` (with a `t`). As you may have noticed in several of the previous assignments, use of the `distplot` function triggers a deprecation warning to notify the user that they should replace all deprecated functions with the updated version. Generally, warnings should not be suppressed but we will do so in this assignment to avoid cluttering.\n",
    "\n",
    "See the seaborn documentation on [distributions](https://seaborn.pydata.org/tutorial/distributions.html) and [functions](https://seaborn.pydata.org/tutorial/function_overview.html) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to suppress all FutureWarnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Breakdown\n",
    "Question | Points\n",
    "--- | ---\n",
    "1a | 1\n",
    "1b | 1\n",
    "1c | 2\n",
    "2 | 3\n",
    "3a | 2\n",
    "3b | 2\n",
    "4 | 2\n",
    "5 | 2\n",
    "6a | 1\n",
    "6b | 1\n",
    "6c | 2\n",
    "6d | 2\n",
    "6e | 1\n",
    "6f | 3\n",
    "7 | 6\n",
    "8 | 6\n",
    "9 | 3\n",
    "10 | 15\n",
    "Total | 55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "p1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Part I - Initial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:41.341673Z",
     "start_time": "2019-04-03T20:17:41.330307Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style = \"whitegrid\", \n",
    "        color_codes = True,\n",
    "        font_scale = 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "loading",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Loading in the Data\n",
    "\n",
    "In email classification, our goal is to classify emails as spam or not spam (referred to as \"ham\") using features generated from the text in the email. \n",
    "\n",
    "The dataset consists of email messages and their labels (0 for ham, 1 for spam). Your labeled training dataset contains 8348 labeled examples, and the unlabeled test set contains 1000 unlabeled examples.\n",
    "\n",
    "Run the following cells to load in the data into DataFrames.\n",
    "\n",
    "The `train` DataFrame contains labeled data that you will use to train your model. It contains four columns:\n",
    "\n",
    "1. `id`: An identifier for the training example\n",
    "1. `subject`: The subject of the email\n",
    "1. `email`: The text of the email\n",
    "1. `spam`: 1 if the email is spam, 0 if the email is ham (not spam)\n",
    "\n",
    "The `test` DataFrame contains 1000 unlabeled emails. You will predict labels for these emails and submit your predictions to the autograder for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.181245Z",
     "start_time": "2019-04-03T20:17:41.343927Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "fetch-data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using version already downloaded: Fri Nov 27 01:33:00 2020\n",
      "MD5 hash of file: 0380c4cf72746622947b9ca5db9b8be8\n",
      "Using version already downloaded: Fri Nov 27 01:33:01 2020\n",
      "MD5 hash of file: a2e7abd8c7d9abf6e6fafc1d1f9ee6bf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subject</th>\n",
       "      <th>email</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: A&amp;L Daily to be auctioned in bankrupt...</td>\n",
       "      <td>url: http://boingboing.net/#85534171\\n date: n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Subject: Wired: \"Stronger ties between ISPs an...</td>\n",
       "      <td>url: http://scriptingnews.userland.com/backiss...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Subject: It's just too small                  ...</td>\n",
       "      <td>&lt;html&gt;\\n &lt;head&gt;\\n &lt;/head&gt;\\n &lt;body&gt;\\n &lt;font siz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Subject: liberal defnitions\\n</td>\n",
       "      <td>depends on how much over spending vs. how much...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Subject: RE: [ILUG] Newbie seeks advice - Suse...</td>\n",
       "      <td>hehe sorry but if you hit caps lock twice the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            subject  \\\n",
       "0   0  Subject: A&L Daily to be auctioned in bankrupt...   \n",
       "1   1  Subject: Wired: \"Stronger ties between ISPs an...   \n",
       "2   2  Subject: It's just too small                  ...   \n",
       "3   3                      Subject: liberal defnitions\\n   \n",
       "4   4  Subject: RE: [ILUG] Newbie seeks advice - Suse...   \n",
       "\n",
       "                                               email  spam  \n",
       "0  url: http://boingboing.net/#85534171\\n date: n...     0  \n",
       "1  url: http://scriptingnews.userland.com/backiss...     0  \n",
       "2  <html>\\n <head>\\n </head>\\n <body>\\n <font siz...     1  \n",
       "3  depends on how much over spending vs. how much...     0  \n",
       "4  hehe sorry but if you hit caps lock twice the ...     0  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import fetch_and_cache_gdrive\n",
    "fetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\n",
    "fetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n",
    "\n",
    "original_training_data = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Convert the emails to lower case as a first step to processing the text\n",
    "original_training_data['email'] = original_training_data['email'].str.lower()\n",
    "test['email'] = test['email'].str.lower()\n",
    "\n",
    "original_training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-34476156ed73b800",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1a\n",
    "First, let's check if our data contains any missing values. Fill in the cell below to print the number of NaN values in each column. If there are NaN values, replace them with appropriate filler values (i.e., NaN values in the `subject` or `email` columns should be replaced with empty strings). Print the number of NaN values in each column after this modification to verify that there are no NaN values left.\n",
    "\n",
    "Note that while there are no NaN values in the `spam` column, we should be careful when replacing NaN labels. Doing so without consideration may introduce significant bias into our model when fitting.\n",
    "\n",
    "*The provided test checks that there are no missing values in your dataset.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.203231Z",
     "start_time": "2019-04-03T20:17:42.185104Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b1fb39d9b651ca1b",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#original_training_data['subject'].isnull().sum().sum()\n",
    "original_training_data['subject'] = original_training_data['subject'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1b\n",
    "\n",
    "In the cell below, print the text of the `email` field for the first ham and the first spam email in the original training set.\n",
    "\n",
    "*The provided tests just ensure that you have assigned `first_ham` and `first_spam` to rows in the data, but only the hidden tests check that you selected the correct observations.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.247245Z",
     "start_time": "2019-04-03T20:17:42.228451Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q1-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: http://boingboing.net/#85534171\n",
      " date: not supplied\n",
      " \n",
      " arts and letters daily, a wonderful and dense blog, has folded up its tent due \n",
      " to the bankruptcy of its parent company. a&l daily will be auctioned off by the \n",
      " receivers. link[1] discuss[2] (_thanks, misha!_)\n",
      " \n",
      " [1] http://www.aldaily.com/\n",
      " [2] http://www.quicktopic.com/boing/h/zlfterjnd6jf\n",
      " \n",
      " \n",
      "\n",
      "<html>\n",
      " <head>\n",
      " </head>\n",
      " <body>\n",
      " <font size=3d\"4\"><b> a man endowed with a 7-8\" hammer is simply<br>\n",
      "  better equipped than a man with a 5-6\"hammer. <br>\n",
      " <br>would you rather have<br>more than enough to get the job done or fall =\n",
      " short. it's totally up<br>to you. our methods are guaranteed to increase y=\n",
      " our size by 1-3\"<br> <a href=3d\"http://209.163.187.47/cgi-bin/index.php?10=\n",
      " 004\">come in here and see how</a>\n",
      " </body>\n",
      " </html>\n",
      " \n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "spam_df = original_training_data[original_training_data['spam'] == 1]\n",
    "ham_df = original_training_data[original_training_data['spam'] == 0]\n",
    "\n",
    "first_ham = ham_df.iloc[0]['email']\n",
    "first_spam = spam_df.iloc[0]['email']\n",
    "print(first_ham)\n",
    "print(first_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 1c\n",
    "\n",
    "Discuss one thing you notice that is different between the two emails that might relate to the identification of spam.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1c\n",
    "manual: True\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Some things I noticed was that the second email was a bit harder to decipher in terms of the actual content, perhaps due to the format. On the other hand, the first email (the one that isn't spam) was far more clear to understand._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-78513403ef52a957",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## Training Validation Split\n",
    "The training data we downloaded is all the data we have available for both training models and **validating** the models that we train.  We therefore need to split the training data into separate training and validation datsets.  You will need this **validation data** to assess the performance of your classifier once you are finished training. Note that we set the seed (random_state) to 42. This will produce a pseudo-random sequence of random numbers that is the same for every student. **Do not modify this in the following questions, as our tests depend on this random seed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.317970Z",
     "start_time": "2019-04-03T20:17:42.294532Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-873194ed3e686dfb",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This creates a 90/10 train-validation split on our labeled data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(original_training_data, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "feat-eng",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Basic Feature Engineering\n",
    "\n",
    "We would like to take the text of an email and predict whether the email is ham or spam. This is a *classification* problem, so we can use logistic regression to train a classifier. Recall that to train an logistic regression model we need a numeric feature matrix $X$ and a vector of corresponding binary labels $y$.  Unfortunately, our data are text, not numbers. To address this, we can create numeric features derived from the email text and use those features for logistic regression.\n",
    "\n",
    "Each row of $X$ is an email. Each column of $X$ contains one feature for all the emails. We'll guide you through creating a simple feature, and you'll create more interesting ones as you try to increase the accuracy of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 2\n",
    "\n",
    "Create a function called `words_in_texts` that takes in a list of `words` and a pandas Series of email `texts`. It should output a 2-dimensional NumPy array containing one row for each email text. The row should contain either a 0 or a 1 for each word in the list: 0 if the word doesn't appear in the text and 1 if the word does. For example:\n",
    "\n",
    "```\n",
    ">>> words_in_texts(['hello', 'bye', 'world'], \n",
    "                   pd.Series(['hello', 'hello worldhello']))\n",
    "\n",
    "array([[1, 0, 0],\n",
    "       [1, 0, 1]])\n",
    "```\n",
    "\n",
    "*The provided tests make sure that your function works correctly, so that you can use it for future questions.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.337281Z",
     "start_time": "2019-04-03T20:17:42.320567Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q2-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 1]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def words_in_texts(words, texts):\n",
    "    '''\n",
    "    Args:\n",
    "        words (list): words to find\n",
    "        texts (Series): strings to search in\n",
    "    \n",
    "    Returns:\n",
    "        NumPy array of 0s and 1s with shape (n, p) where n is the\n",
    "        number of texts and p is the number of words.\n",
    "    '''\n",
    "    lst = []\n",
    "    for word in words:\n",
    "        lst.append(texts.str.contains(word))\n",
    "    indicator_df = pd.DataFrame(lst)\n",
    "    indicator_array = indicator_df.astype(int).to_numpy().transpose()\n",
    "    return indicator_array\n",
    "\n",
    "words_in_texts(['hello', 'bye', 'world'], pd.Series(['hello', 'hello worldhello']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "eda",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Basic EDA\n",
    "\n",
    "We need to identify some features that allow us to distinguish spam emails from ham emails. One idea is to compare the distribution of a single feature in spam emails to the distribution of the same feature in ham emails. If the feature is itself a binary indicator, such as whether a certain word occurs in the text, this amounts to comparing the proportion of spam emails with the word to the proportion of ham emails with the word.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "The following plot (which was created using `sns.barplot`) compares the proportion of emails in each class containing a particular set of words. \n",
    "\n",
    "![training conditional proportions](images/training_conditional_proportions.png)\n",
    "\n",
    "You can use DataFrame's `.melt` method to \"unpivot\" a DataFrame. See the following code cell for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.428419Z",
     "start_time": "2019-04-03T20:17:42.386697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_1  word_2  type\n",
       "0       1       0  spam\n",
       "1       0       1   ham\n",
       "2       1       0   ham\n",
       "3       0       1   ham"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>word_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>word_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>word_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>word_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>word_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>word_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>word_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>word_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type variable  value\n",
       "0  spam   word_1      1\n",
       "1   ham   word_1      0\n",
       "2   ham   word_1      1\n",
       "3   ham   word_1      0\n",
       "4  spam   word_2      0\n",
       "5   ham   word_2      1\n",
       "6   ham   word_2      0\n",
       "7   ham   word_2      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "df = pd.DataFrame({\n",
    "    'word_1': [1, 0, 1, 0],\n",
    "    'word_2': [0, 1, 0, 1],\n",
    "    'type': ['spam', 'ham', 'ham', 'ham']\n",
    "})\n",
    "display(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\n",
    "display(df);\n",
    "display(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\n",
    "display(df.melt(\"type\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3a\n",
    "\n",
    "Create a bar chart like the one above comparing the proportion of spam and ham emails containing certain words. Choose a set of words that are different from the ones above, but also have different proportions for the two classes. Make sure to only consider emails from `train`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "manual: True\n",
    "format: image\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:43.145246Z",
     "start_time": "2019-04-03T20:17:42.430406Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "q3a-answer",
     "locked": false,
     "points": 2,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\n",
    "\n",
    "word_list = ['thanks', 'special', 'now', 'deal', 'well', 'purchase']\n",
    "\n",
    "\n",
    "ham_words = words_in_texts(word_list, train[train['spam'] == 0]['email'])\n",
    "ham_words_df = pd.DataFrame(ham_words)\n",
    "spam_words = words_in_texts(word_list, train[train['spam'] == 1]['email'])\n",
    "spam_words_df = pd.DataFrame(spam_words)\n",
    "\n",
    "ham_words_df = ham_words_df.rename(columns = {0: word_list[0], 1: word_list[1], 3: word_list[3], 4: word_list[4], 5: word_list[5]})\n",
    "spam_words_df = spam_words_df.rename(columns = {0: word_list[0], 1: word_list[1], 3: word_list[3], 4: word_list[4], 5: word_list[5]})\n",
    "\n",
    "\n",
    "\n",
    "ham_props = (ham_words_df.sum()/len(ham_words)).tolist()\n",
    "spam_props = (spam_words_df.sum()/len(spam_words)).tolist()\n",
    "\n",
    "props = {word_list[0]: [ham_props[0], spam_props[0]],\n",
    "        word_list[1]: [ham_props[1], spam_props[1]],\n",
    "        word_list[2]: [ham_props[2], spam_props[2]],\n",
    "        word_list[3]: [ham_props[3], spam_props[3]],\n",
    "        word_list[4]: [ham_props[4], spam_props[4]],\n",
    "        word_list[5]: [ham_props[5], spam_props[5]]}\n",
    "\n",
    "             \n",
    "\n",
    "props_df = pd.DataFrame(data=props)\n",
    "props_df['spam'] = ['Ham', 'Spam']\n",
    "props_df = props_df.melt('spam')\n",
    "\n",
    "ax = sns.barplot(x='variable', y='value', hue='spam', data=props_df)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel(\"Word\")\n",
    "plt.ylabel(\"Proportion of Emails\")\n",
    "plt.title(\"Frequency of Words in Ham/Spam Emails\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "When the feature is binary, it makes sense to compare its proportions across classes (as in the previous question). Otherwise, if the feature can take on numeric values, we can compare the distributions of these values for different classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3b\n",
    "\n",
    "![training conditional densities](images/training_conditional_densities.png)\n",
    "\n",
    "Create a *class conditional density plot* like the one above (using `sns.distplot`), comparing the distribution of the length of spam emails to the distribution of the length of ham emails in the training set. Set the x-axis limit from 0 to 50000.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3b\n",
    "manual: True\n",
    "format: image\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:43.492661Z",
     "start_time": "2019-04-03T20:17:43.149431Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "q3b-answer",
     "locked": false,
     "points": 2,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length = []\n",
    "\n",
    "for email in train['email']:\n",
    "    length.append(len(email))\n",
    "    \n",
    "train['length'] = length\n",
    "\n",
    "ham_len = train[train['spam'] == 0]['length']\n",
    "spam_len = train[train['spam'] == 1]['length']\n",
    "\n",
    "sns.distplot(ham_len, hist=False, label='Ham')\n",
    "sns.distplot(spam_len, hist=False, label='Spam')\n",
    "\n",
    "plt.xlim(0, 50000)\n",
    "plt.xlabel('Length of email body')\n",
    "plt.ylabel('Distribution')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig('training_conditional_densities.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "classification",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "# Basic Classification\n",
    "\n",
    "Notice that the output of `words_in_texts(words, train['email'])` is a numeric matrix containing features for each email. This means we can use it directly to train a classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q4",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 4\n",
    "\n",
    "We've given you 5 words that might be useful as features to distinguish spam/ham emails. Use these words as well as the `train` DataFrame to create two NumPy arrays: `X_train` and `Y_train`.\n",
    "\n",
    "`X_train` should be a matrix of 0s and 1s created by using your `words_in_texts` function on all the emails in the training set.\n",
    "\n",
    "`Y_train` should be a vector of the correct labels for each email in the training set.\n",
    "\n",
    "*The provided tests check that the dimensions of your feature matrix (X) are correct, and that your features and labels are binary (i.e. consists of only 0's and 1's). It does not check that your function is correct; that was verified in a previous question.*\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:43.726012Z",
     "start_time": "2019-04-03T20:17:43.498088Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q4-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0]]),\n",
       " 0    0\n",
       " 1    0\n",
       " 2    0\n",
       " 3    0\n",
       " 4    0\n",
       " Name: spam, dtype: int64)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n",
    "\n",
    "X_train = words_in_texts(some_words, train['email'])\n",
    "Y_train = train['spam']\n",
    "\n",
    "X_train[:5], Y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q5",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 5\n",
    "\n",
    "Now that we have matrices, we can build a model with `scikit-learn`! Using the [`LogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) classifier, train a logistic regression model using `X_train` and `Y_train`. Then, output the model's training accuracy below. You should get an accuracy of around $0.75$\n",
    "\n",
    "*The provided test checks that you initialized your logistic regression model correctly.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:44.593918Z",
     "start_time": "2019-04-03T20:17:43.783872Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q5-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.7576201251164648\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "model.predict(X_train)\n",
    "\n",
    "training_accuracy = model.score(X_train, Y_train)\n",
    "print(\"Training Accuracy: \", training_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't seem too shabby! But the classifier you made above isn't as good as the accuracy would make you believe. First, we are evaluating accuracy on the training set, which may provide a misleading accuracy measure. Accuracy on the training set doesn't always translate to accuracy in the real world (on the test set). In future parts of this analysis, we will hold out some of our data for model validation and comparison.\n",
    "\n",
    "Presumably, our classifier will be used for **filtering**, i.e. preventing messages labeled `spam` from reaching someone's inbox. There are two kinds of errors we can make:\n",
    "- False positive (FP): a ham email gets flagged as spam and filtered out of the inbox.\n",
    "- False negative (FN): a spam email gets mislabeled as ham and ends up in the inbox.\n",
    "\n",
    "To be clear, we label spam emails as 1 and ham emails as 0. These definitions depend both on the true labels and the predicted labels. False positives and false negatives may be of differing importance, leading us to consider more ways of evaluating a classifier, in addition to overall accuracy:\n",
    "\n",
    "**Precision** measures the proportion $\\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$ of emails flagged as spam that are actually spam.\n",
    "\n",
    "**Recall** measures the proportion $\\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$ of spam emails that were correctly flagged as spam. \n",
    "\n",
    "**False-alarm rate** measures the proportion $\\frac{\\text{FP}}{\\text{FP} + \\text{TN}}$ of ham emails that were incorrectly flagged as spam. \n",
    "\n",
    "The two graphics below may help you understand precision and recall visually:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/700px-Precisionrecall.svg.png\" width=\"500px\">\n",
    "\n",
    "Note that a true positive (TP) is a spam email that is classified as spam, and a true negative (TN) is a ham email that is classified as ham."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q6",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 6a\n",
    "\n",
    "Suppose we have a classifier `zero_predictor` that always predicts 0 (never predicts positive). How many false positives and false negatives would this classifier have if it were evaluated on the training set and its results were compared to `Y_train`? Fill in the variables below (feel free to hard code your answers for this part):\n",
    "\n",
    "*Tests in Question 6 only check that you have assigned appropriate types of values to each response variable, but do not check that your answers are correct.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:20:13.853633Z",
     "start_time": "2019-04-03T20:20:13.825724Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q6a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1918)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_predictor_fp = 0\n",
    "zero_predictor_fn = np.count_nonzero(Y_train)\n",
    "zero_predictor_fp, zero_predictor_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q6a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 6b\n",
    "\n",
    "What is the accuracy and recall of `zero_predictor` (classifies every email as ham) on the training set? Do **NOT** use any `sklearn` functions.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6b\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:23:21.553134Z",
     "start_time": "2019-04-03T20:23:21.548219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7447091707706642, 0)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero = np.zeros(len(Y_train))\n",
    "zero_predictor_acc = np.count_nonzero(zero==Y_train)/len(Y_train)\n",
    "zero_predictor_recall = 0\n",
    "zero_predictor_acc, zero_predictor_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q6b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6c\n",
    "\n",
    "Provide brief explanations of the results from 6a and 6b. Why do we observe each of these values (FP, FN, accuracy, recall)?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6c\n",
    "manual: True\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_For 6a, the number of false positives must be 0 because, as a zero predictor, nothing will be markets positive as a spam. The number of false negatives, on the other hand, is the number of positive spam emails in y-train since the zero predictor we know marks all positive spam emails as negative._\n",
    "\n",
    "_For 6b, the accuracy is the proportion of negative values within all the emails because the zero predictor correctly marks the emails that aren't spam. The recall, on the other hand, must be 0 because the number of true_positives has to be 0 with the zero predictor since no emails will be market positive anyways._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Question 6d\n",
    "\n",
    "Compute the precision, recall, and false-alarm rate of the `LogisticRegression` classifier created and trained in Question 5. Do **NOT** use any `sklearn` functions.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6d\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:37:54.875265Z",
     "start_time": "2019-04-03T20:37:54.720667Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_train_hat = model.predict(X_train)\n",
    "\n",
    "true_positive = 0\n",
    "true_negative = 0\n",
    "false_positive = 0\n",
    "false_negative = 0\n",
    "\n",
    "for i in range(len(Y_train_hat)):\n",
    "    if Y_train[i] == True:\n",
    "        if Y_train_hat[i] == True:\n",
    "            true_positive+=1\n",
    "        else:\n",
    "            false_negative+=1\n",
    "    else:\n",
    "        if Y_train_hat[i] == True:\n",
    "            false_positive+=1\n",
    "        else:\n",
    "            true_negative+=1\n",
    "\n",
    "\n",
    "\n",
    "logistic_predictor_precision = np.count_nonzero(Y_train_hat==1)\n",
    "logistic_predictor_recall = true_positive/(true_positive+false_negative)\n",
    "logistic_predictor_far = false_positive/(false_positive+true_negative)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q6d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6e\n",
    "\n",
    "Are there more false positives or false negatives when using the logistic regression classifier from Question 5?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6e\n",
    "manual: True\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_There are substantially more false negatives when using logistic regression than false positives. Specifically, there were 122 false positives and 1699 false negatives._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6f\n",
    "\n",
    "1. Our logistic regression classifier got 75.76% prediction accuracy (number of correct predictions / total). How does this compare with predicting 0 for every email?\n",
    "1. Given the word features we gave you above, name one reason this classifier is performing poorly. Hint: Think about how prevalent these words are in the email set.\n",
    "1. Which of these two classifiers would you prefer for a spam filter and why? Describe your reasoning and relate it to at least one of the evaluation metrics you have computed so far.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6f\n",
    "manual: True\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_1. The logistic regression classifier was slightly more accurate at predicting since the zero predictor had an accuracy of around 75.47%. However, this difference isn't as significant as one would hope._\n",
    "\n",
    "_2.One reason the classifier could be performing so poorly is because the words we chose aren't common enough for there to be a substantial amount of emails for the classifier to use._\n",
    "\n",
    "_3.Though in terms of accuracy they wee both not too far off, I would still perfer the logistic regression classfier simply because, if we had used more common words, I think it would have performed bettter. Essentially, the logistic regression classifier can be tweaked and worked on to classify better, but simply predicting 0 for each email with the zero predictor isn't truly classifying anything and, in terms of the metrics we computed, since the number of true positives with the zero classifier will always be 0, the precision and recall will also be 0._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "p2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "# Part II - Moving Forward\n",
    "\n",
    "With this in mind, it is now your task to make the spam filter more accurate. In order to get full credit on the accuracy part of this assignment, you must get at least **88%** accuracy on the test set. To see your accuracy on the test set, you will use your classifier to predict every email in the `test` DataFrame and upload your predictions to Gradescope.\n",
    "\n",
    "**Gradescope limits you to four submissions per day**. This means you should start early so you have time if needed to refine your model. You will be able to see your accuracy on 70% of the test set when submitting to Gradescope, but we will be evaluating your model on the entire test set so try to score slightly above 88% on gradescope if you can.\n",
    "\n",
    "Here are some ideas for improving your model:\n",
    "\n",
    "1. Finding better features based on the email text. Some example features are:\n",
    "    1. Number of characters in the subject / body\n",
    "    1. Number of words in the subject / body\n",
    "    1. Use of punctuation (e.g., how many '!'s were there?)\n",
    "    1. Number / percentage of capital letters \n",
    "    1. Whether the email is a reply to an earlier email or a forwarded email\n",
    "1. Finding better (and/or more) words to use as features. Which words are the best at distinguishing emails? This requires digging into the email text itself. \n",
    "1. Better data processing. For example, many emails contain HTML as well as text. You can consider extracting out the text from the HTML to help you find better words. Or, you can match HTML tags themselves, or even some combination of the two.\n",
    "1. Model selection. You can adjust parameters of your model (e.g. the regularization parameter) to achieve higher accuracy. Recall that you should use cross-validation to do feature and model selection properly! Otherwise, you will likely overfit to your training data.\n",
    "\n",
    "You may use whatever method you prefer in order to create features, but **you are not allowed to import any external feature extraction libraries**. In addition, **you are only allowed to train logistic regression models**. No random forests, k-nearest-neighbors, neural nets, etc.\n",
    "\n",
    "We have not provided any code to do this, so feel free to create as many cells as you need in order to tackle this task. However, answering questions 7, 8, and 9 should help guide you.\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** *You may want to use your **validation data** to evaluate your model and get a better sense of how it will perform on the test set.* Note, however, that you may overfit to your validation set if you try to optimize your validation accuracy too much.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-154-aa5f5588031f>:45: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  proportions = ham_proportions/spam_proportions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.97538257, 0.97272122, 0.97005988, 0.97403462, 0.97003995])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "\n",
    "total_times = {}\n",
    "\n",
    "emails = train[\"email\"].ravel()\n",
    "\n",
    "for i in range(len(emails)):\n",
    "    current = [emails[i]][0].split()\n",
    "    looks = []\n",
    "    for j in range(len(current)):\n",
    "        word = current[j]\n",
    "        if word not in looks:\n",
    "            looks.append(word)\n",
    "            if word not in total_times:\n",
    "                total_times[word] = 1\n",
    "            else:\n",
    "                total_times[word] += 1\n",
    "                        \n",
    "dict_sorted = {k: v for k, v in sorted(total_times.items(), key=lambda item: item[1]) if v > 50}\n",
    "#dict_sorted\n",
    "words = list(sorted_dict.keys())\n",
    "\n",
    "\n",
    "def filtered(item):\n",
    "    unwanted = ['>', '<', '[', ']', '=', '(', ')', '+', '?', ',', '%', ':', '$', '\"', '/', '*', '@', '.', '_', ';', ' ', '-']\n",
    "    for thing in unwanted:\n",
    "        if thing in item:\n",
    "            return False\n",
    "    return True\n",
    "    \n",
    "words_sorted = list(filter(filtered, words))\n",
    "#words_sorted\n",
    "\n",
    "words_ham = words_in_texts(words_sorted, train[train[\"spam\"] == 0][\"email\"])\n",
    "words_spam = words_in_texts(words_sorted, train[train[\"spam\"] == 1][\"email\"])\n",
    "\n",
    "ham_words_df = pd.DataFrame(words_ham)\n",
    "ham_proportions = (ham_words_df.sum()/len(words_ham)).values\n",
    "\n",
    "spam_words_df = pd.DataFrame(words_spam)\n",
    "spam_proportions = (spam_words_df.sum()/len(words_spam)).values\n",
    "\n",
    "final_words = []\n",
    "proportions = ham_proportions/spam_proportions\n",
    "\n",
    "\n",
    "\n",
    "for k in range(len(words_sorted)):\n",
    "    x = proportions[k] \n",
    "    if (x > 8 or x < 0.4) and (x != float(\"inf\")):\n",
    "        final_words.append(words_sorted[k])\n",
    "\n",
    "X_train = words_in_texts(final_words, train[\"email\"])\n",
    "model = LogisticRegression()\n",
    "cross_vals = cross_val_score(model, X_train, Y_train, cv=5)\n",
    "cross_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9700598802395209"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test on validation\n",
    "model = LogisticRegression()\n",
    "X_val_test = words_in_texts(final_words, val['email'])\n",
    "Y_val = val['spam']\n",
    "model.fit(X_train, Y_train)\n",
    "val_pred = model.predict(X_val_test)\n",
    "accuracy = model.score(X_val_test, Y_val)\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q7",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 7: Feature/Model Selection Process\n",
    "\n",
    "In this following cell, describe the process of improving your model. You should use at least 2-3 sentences each to address the follow questions:\n",
    "\n",
    "1. How did you find better features for your model?\n",
    "2. What did you try that worked or didn't work?\n",
    "3. What was surprising in your search for good features?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7\n",
    "manual: True\n",
    "points: 6\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_1. I used the approach of finding better words as features, and I did this by filtering out words that weren't as common, using only frequently used words so my sample size was smaller. I also compared the spam and ham proportions, filtering out significant differences, where words were frequent in spam but on in ham, or vice versa._\n",
    "\n",
    "_2. After many, MANY tries, I ended up using a lower threshold for the number of emails a word can be in to reduce run time and ensure words being used were actually signficant. I also used cross validation on the cv score so that we could avoid overfitting, which I was worried about. Overall, I didn't want to go too complicated because my dataset was already huge and the runtime was extremely long already so each time I wanted to see if it was working, it would take forever. It was really frustrating because my runtime was  super long, especially when I first started, so I had to figure out how to lower it as much as possible. I assumed it was either the for-loop or the amount of times I was originally calling on words_in_texts, and since I knew regex was not my strong suit (to say the least ...), I had to rework the rest of the code to make sure that we don't run words_in_texts as much, which was a struggle. It's still not perfect -- I definitely think there could have been more ways to reduce the runtime because it's still pretty long -- but it runs a little faster now so at this point I'll take it._\n",
    "\n",
    "_3. I was the most shocked/surprised by the runtime. At first it was literally taking me 2 minutes for things to run and it wouldn't even go through the whole code because there were bugs halfway through or something. I kind of attribute it to using words_in_texts as my primary feature finder because there are a lot of words that needed to be classified, but at the same time, the runtime still isn't super low for me yet, so there's probably other things contributing to that. It was just frustrating to debug my code because each time it would take ages to see if something worked._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q8",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### Question 8: EDA\n",
    "\n",
    "In the cell below, show a visualization that you used to select features for your model. \n",
    "\n",
    "Include:\n",
    "\n",
    "1. A plot showing something meaningful about the data that helped you during feature selection, model selection, or both.\n",
    "2. Two or three sentences describing what you plotted and its implications with respect to your features.\n",
    "\n",
    "Feel free to create as many plots as you want in your process of feature selection, but select only one for the response cell below.\n",
    "\n",
    "**You should not just produce an identical visualization to question 3.** Specifically, don't show us a bar chart of proportions, or a one-dimensional class-conditional density plot. Any other plot is acceptable, **as long as it comes with thoughtful commentary.** Here are some ideas:\n",
    "\n",
    "1. Consider the correlation between multiple features (look up correlation plots and `sns.heatmap`). \n",
    "1. Try to show redundancy in a group of features (e.g. `body` and `html` might co-occur relatively frequently, or you might be able to design a feature that captures all html tags and compare it to these). \n",
    "1. Visualize which words have high or low values for some useful statistic.\n",
    "1. Visually depict whether spam emails tend to be wordier (in some sense) than ham emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Generate your visualization in the cell below and provide your description in a comment.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8\n",
    "manual: True\n",
    "format: image\n",
    "points: 6\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T00:27:36.170465Z",
     "start_time": "2019-04-02T00:27:36.167776Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "q8-eda",
     "locked": false,
     "points": 3,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student",
     "written",
     "q_eda1"
    ]
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-9a1a803cfa17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mwords_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mham_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords_in_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_sorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"spam\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"email\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mspam_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords_in_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_sorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"spam\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"email\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-138-6e81561e6d7a>\u001b[0m in \u001b[0;36mwords_in_texts\u001b[0;34m(words, texts)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mlst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mindicator_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mindicator_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindicator_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1999\u001b[0m                 )\n\u001b[1;32m   2000\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2001\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mcontains\u001b[0;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mforbid_nonstring_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bytes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m         result = str_contains(\n\u001b[0m\u001b[1;32m   2825\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mstr_contains\u001b[0;34m(arr, pat, case, flags, na, regex)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0muppered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muppered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_na_map\u001b[0;34m(f, arr, na_result, dtype)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mna_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mna_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_map_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_map_object\u001b[0;34m(f, arr, na_mask, na_value, dtype)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mconvert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;31m# Reraise the exception if callable `f` got wrong number of args.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer_mask\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    447\u001b[0m             )\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Write your description (2-3 sentences) as a comment here:\n",
    "# So, for my feature selection, I wanted to see what is a good parameter for assessing the number of emails a word should be in for it to be significant enough to include in the model. I am doing this by assessing the accuracy score for the validation data. By figuring out the best threshold to cap the emails at, this will give me a better chance at having a strong classifier.\n",
    "#When I originally did this, my email threshold was an array from 50 to 1000 skipping at 50 each time, but this code was literally running for an hour and it still wasn't done so I had to intervene. I essentially made my own judgement to increase the amount skipped by from 50 to 100 and lower the upper bound from 1000 to 500. This obviously is no longer accurate as it skips a lot of possiblities that would provide a more accurate classifier, but I simply couldn't justify that insane runtime.\n",
    "\n",
    "# Write the code to generate your visualization here:\n",
    "\n",
    "                \n",
    "accuracies = []\n",
    "total_accuracies = []\n",
    "email_threshold = np.arange(50, 500, 100)\n",
    "\n",
    "for threshold in range(len(thresholds)-1):\n",
    "    sort_dict = {k: v for k, v in sorted(total_times.items(), key=lambda item: item[1]) if v > email_threshold[threshold]}\n",
    "    total_accuracies = []\n",
    "\n",
    "    words = list(sorted_dict.keys())\n",
    "    \n",
    "    def filtered(item):\n",
    "        unwanted = ['>', '<', '[', ']', '=', '(', ')', '+', '?', ',', '%', ':', '$', '\"', '/', '*', '@', '.', '_', ';', '-']\n",
    "        for thing in unwanted:\n",
    "            if thing in item:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    words_sorted = list(filter(filtered, words))\n",
    "    \n",
    "    ham_words = words_in_texts(words_sorted, train[train[\"spam\"] == 0][\"email\"])\n",
    "    spam_words = words_in_texts(words_sorted, train[train[\"spam\"] == 1][\"email\"])\n",
    "    \n",
    "    ham_df = pd.DataFrame(ham_words)\n",
    "    ham_proportions = (ham_df.sum()/len(ham_words))\n",
    "    \n",
    "    spam_df = pd.DataFrame(spam_words)\n",
    "    spam_proportions = (spam_df.sum()/len(spam_words))\n",
    "\n",
    "    prop_range_high = np.arange(5, 11)\n",
    "    prop_range_low = np.arange(0.1, 0.7, 0.1)\n",
    "    \n",
    "    filtered_words = []\n",
    "    proportions = ham_proportions/spam_proportions\n",
    "    \n",
    "    for prop in range(len(prop_range_high)):\n",
    "        high = prop_range_high[prop]\n",
    "        low = prop_range_low[prop]\n",
    "        for k in range(len(words_sorted)):\n",
    "            x = proportions[k] \n",
    "            if (x > high or x < low) and (x != float(\"inf\")):\n",
    "                filtered_words.append(words_sorted[k])\n",
    "\n",
    "        X_train = words_in_texts(filtered_words, train[\"email\"])\n",
    "        X_val = words_in_texts(filtered_words, val[\"email\"])\n",
    "        Y_val = val[\"spam\"]\n",
    "        model = LogisticRegression()\n",
    "        model.fit(X_train, Y_train)\n",
    "        val_predicted = model.predict(X_val)\n",
    "        accuracy = model.score(X_val, Y_val)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "    total_accuracies.append(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_df = pd.DataFrame(total_accuracies, index=email_threshold)\n",
    "accuracies_df.rename(columns={0: \"<0.1 and >5\",\n",
    "                              1: \"<0.2 and >6\",\n",
    "                              2: \"<0.3 and >7\",\n",
    "                              3: \"<0.4 and >8\",\n",
    "                              4: \"<0.9 and >9\",\n",
    "                              5: \"<1.0 and >10\"})\n",
    "sns.heatmap(data=accuracies_df)\n",
    "plt.xlabel('Spam and Ham Proportion Bounds')\n",
    "plt.ylabel('Number of Appearances in an Email Thresholds')\n",
    "plt.title(\"Validation Data Accuracy Scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q9",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 9: ROC Curve\n",
    "\n",
    "In most cases we won't be able to get 0 false positives and 0 false negatives, so we have to compromise. For example, in the case of cancer screenings, false negatives are comparatively worse than false positives — a false negative means that a patient might not discover that they have cancer until it's too late, whereas a patient can just receive another screening for a false positive.\n",
    "\n",
    "Recall that logistic regression calculates the probability that an example belongs to a certain class. Then, to classify an example we say that an email is spam if our classifier gives it $\\ge 0.5$ probability of being spam. However, *we can adjust that cutoff*: we can say that an email is spam only if our classifier gives it $\\ge 0.7$ probability of being spam, for example. This is how we can trade off false positives and false negatives.\n",
    "\n",
    "The ROC curve shows this trade off for each possible cutoff probability. In the cell below, plot a ROC curve for your final classifier (the one you use to make predictions for Gradescope) on the training data. Refer to Lecture 19 or [Section 17.7](https://www.textbook.ds100.org/ch/17/classification_sensitivity_specificity.html) of the course text to see how to plot an ROC curve.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q9\n",
    "manual: True\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Note that you'll want to use the .predict_proba(...) method for your classifier\n",
    "# instead of .predict(...) so you get probabilities, not classes\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q10",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# Question 10: Test Predictions\n",
    "\n",
    "The following code will write your predictions on the test dataset to a CSV file. **You will need to submit this file to the \"Project 2 Test Predictions\" assignment on Gradescope to get credit for this question.**\n",
    "\n",
    "Save your predictions in a 1-dimensional array called `test_predictions`. **Please make sure you've saved your predictions to `test_predictions` as this is how part of your score for this question will be determined.**\n",
    "\n",
    "Remember that if you've performed transformations or featurization on the training data, you must also perform the same transformations on the test data in order to make predictions. For example, if you've created features for the words \"drug\" and \"money\" on the training data, you must also extract the same features in order to use scikit-learn's `.predict(...)` method.\n",
    "\n",
    "**Note: You may submit up to 4 times a day. If you have submitted 4 times on a day, you will need to wait until the next day for more submissions.**\n",
    "\n",
    "Note that this question is graded on an absolute scale based on the accuracy your model achieves on the overall test set, and as such, your score does not depend on your ranking on Gradescope. Your public Gradescope results are based off of your classifier's accuracy on 70% of the test dataset and your score for this question will be based off of your classifier's accuracy on 100% of the test set.\n",
    "\n",
    "*The provided tests check that your predictions are in the correct format, but you must additionally submit to Gradescope to evaluate your classifier accuracy.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q10\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T00:27:38.650695Z",
     "start_time": "2019-04-02T00:27:38.469233Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q10-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "X_test = words_in_texts(final_words, test['email'])\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "test_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d15e30e2a961277d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "The following cell generates a CSV file with your predictions. **You must submit this CSV file to the \"Project 2 Test Predictions\" assignment on Gradescope to get credit for this question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T00:27:39.986326Z",
     "start_time": "2019-04-02T00:27:38.385Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8dd1bfadcbe08b00",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a CSV file: submission_2020-12-01T02:36:26.csv.\n",
      "You may now upload this CSV file to Gradescope for scoring.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Assuming that your predictions on the test set are stored in a 1-dimensional array called\n",
    "# test_predictions. Feel free to modify this cell as long you create a CSV in the right format.\n",
    "\n",
    "# Construct and save the submission:\n",
    "submission_df = pd.DataFrame({\n",
    "    \"Id\": test['id'], \n",
    "    \"Class\": test_predictions,\n",
    "}, columns=['Id', 'Class'])\n",
    "timestamp = datetime.isoformat(datetime.now()).split(\".\")[0]\n",
    "submission_df.to_csv(\"submission_{}.csv\".format(timestamp), index=False)\n",
    "\n",
    "print('Created a CSV file: {}.'.format(\"submission_{}.csv\".format(timestamp)))\n",
    "print('You may now upload this CSV file to Gradescope for scoring.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <p>Your submission has been exported. Click <a href=\"proj2.zip\" target=\"_blank\">here</a> \n",
       "                to download the zip file.</p>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(\"proj2.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "history": [
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\n\n# BEGIN SOLUTION\nsome_words = ['opportunity', 'bank', 'receive', 'dear', 'best', 'deal']\nPhi_train = words_in_texts(some_words, train['email'])\n\ndf = pd.DataFrame(data = Phi_train, columns = some_words)\ndf['label'] = train['spam']\n\nplt.figure(figsize=(12,8))\nsns.barplot(x = \"variable\", \n            y = \"value\", \n            hue = \"label\", \n            data = (df\n                    .replace({'label': \n                                {0 : 'Ham', \n                                 1 : 'Spam'}})\n                    .melt('label')\n                    .groupby(['label', 'variable'])\n                    .mean()\n                    .reset_index()))\n\nplt.xlabel('Words')\nplt.ylabel('Proportion of Emails')\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\")\nplt.tight_layout()\nplt.show()\n# END SOLUTION",
    "id": "3da1bb8528f1420d8e4b01106abb0d1c",
    "idx": 33,
    "time": "2020-11-13T17:39:00.446Z",
    "type": "execution"
   },
   {
    "id": "3da1bb8528f1420d8e4b01106abb0d1c",
    "time": "2020-11-13T17:39:00.597Z",
    "type": "completion"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "bf4059a762a047a6a8e4179dc2c11815",
    "idx": 5,
    "time": "2020-11-13T17:39:15.247Z",
    "type": "execution"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "679de399389b410fbd1bd229389869ba",
    "idx": 8,
    "time": "2020-11-13T17:39:15.251Z",
    "type": "execution"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "668f75f782c041508f9e0c8f82311ad1",
    "idx": 10,
    "time": "2020-11-13T17:39:15.256Z",
    "type": "execution"
   },
   {
    "code": "# BEGIN SOLUTION\nprint('Before imputation:')\nprint(original_training_data.isnull().sum())\noriginal_training_data = original_training_data.fillna('')\nprint('------------')\nprint('After imputation:')\nprint(original_training_data.isnull().sum())\n# END SOLUTION",
    "id": "68e38b511a2c4f5480d4eda2b0082a11",
    "idx": 12,
    "time": "2020-11-13T17:39:15.259Z",
    "type": "execution"
   },
   {
    "code": "# TEST\noriginal_training_data.isnull().sum().sum() == 0",
    "id": "7f4b00c62776443e817cd5a255aa14b9",
    "idx": 13,
    "time": "2020-11-13T17:39:15.261Z",
    "type": "execution"
   },
   {
    "code": "first_ham = original_training_data.loc[original_training_data['spam'] == 0, 'email'].iloc[0] # SOLUTION\nfirst_spam = original_training_data.loc[original_training_data['spam'] == 1, 'email'].iloc[0] # SOLUTION\nprint(first_ham)\nprint(first_spam)",
    "id": "bfb55fdfdfb1456785bb78790aad426b",
    "idx": 15,
    "time": "2020-11-13T17:39:15.264Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nlen(first_ham) > 0 and first_ham[:0] == ''",
    "id": "6345c5019a384a618017acbb080996d9",
    "idx": 16,
    "time": "2020-11-13T17:39:15.265Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nlen(first_spam) > 0 and first_spam[:0] == ''",
    "id": "ee844f20ed0a41c4b81ff495fe482bdf",
    "idx": 17,
    "time": "2020-11-13T17:39:15.268Z",
    "type": "execution"
   },
   {
    "code": "# HIDDEN TEST\noriginal_training_data.loc[original_training_data['spam'] == 0, 'email'].iloc[0] in first_ham",
    "id": "13a350f12fac4931be17235a1daf0a93",
    "idx": 18,
    "time": "2020-11-13T17:39:15.270Z",
    "type": "execution"
   },
   {
    "code": "# HIDDEN TEST\noriginal_training_data.loc[original_training_data['spam'] == 1, 'email'].iloc[0] in first_spam",
    "id": "a90683e4a73346878a06d732d7101c87",
    "idx": 19,
    "time": "2020-11-13T17:39:15.272Z",
    "type": "execution"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "7523257e508447369ca710ce27eba7b1",
    "idx": 23,
    "time": "2020-11-13T17:39:15.276Z",
    "type": "execution"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = 1 * np.array([texts.str.contains(word) for word in words]).T # SOLUTION\n    return indicator_array",
    "id": "81aa3a295d054268acb33351ad567192",
    "idx": 26,
    "time": "2020-11-13T17:39:15.279Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nnp.allclose(words_in_texts(['hello', 'bye', 'world'], \n                           pd.Series(['hello', 'hello worldhello'])),\n            np.array([[1, 0, 0], \n                      [1, 0, 1]]))",
    "id": "690ffc0aa5e446949b45a8b4ecd76f85",
    "idx": 27,
    "time": "2020-11-13T17:39:15.282Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nnp.allclose(words_in_texts(['a', 'b', 'c', 'd', 'e', 'f', 'g'], \n                           pd.Series(['a b c d ef g', 'a', 'b', 'c', 'd e f g', 'h', 'a h'])),\n            np.array([[1,1,1,1,1,1,1], \n                      [1,0,0,0,0,0,0],\n                      [0,1,0,0,0,0,0],\n                      [0,0,1,0,0,0,0],\n                      [0,0,0,1,1,1,1],\n                      [0,0,0,0,0,0,0],\n                      [1,0,0,0,0,0,0]]))",
    "id": "c3fba6032da048efaf5bf9b349cfb4f8",
    "idx": 28,
    "time": "2020-11-13T17:39:15.284Z",
    "type": "execution"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "c248bceea6bd440c870eb7f942fcf77e",
    "idx": 31,
    "time": "2020-11-13T17:39:15.289Z",
    "type": "execution"
   },
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\n\n# BEGIN SOLUTION\nsome_words = ['opportunity', 'bank', 'receive', 'dear', 'best', 'deal']\nPhi_train = words_in_texts(some_words, train['email'])\n\ndf = pd.DataFrame(data = Phi_train, columns = some_words)\ndf['label'] = train['spam']\n\nplt.figure(figsize=(12,8))\nsns.barplot(x = \"variable\", \n            y = \"value\", \n            hue = \"label\", \n            data = (df\n                    .replace({'label': \n                                {0 : 'Ham', \n                                 1 : 'Spam'}})\n                    .melt('label')\n                    .groupby(['label', 'variable'])\n                    .mean()\n                    .reset_index()))\n\nplt.xlabel('Words')\nplt.ylabel('Proportion of Emails')\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\")\nplt.tight_layout()\nplt.show()\n# END SOLUTION",
    "id": "3da1bb8528f1420d8e4b01106abb0d1c",
    "idx": 33,
    "time": "2020-11-13T17:39:15.291Z",
    "type": "execution"
   },
   {
    "code": "# BEGIN SOLUTION\ntmp = train.copy()\ntmp['length'] = tmp['email'].str.len()\nplt.figure(figsize=(10, 6))\nsns.distplot(tmp.loc[tmp['spam'] == 0, 'length'],hist=False, label='Ham')\nsns.distplot(tmp.loc[tmp['spam'] == 1, 'length'],hist=False, label='Spam')\nplt.title('Distribution of Email Body Length')\nplt.xlabel('Length of email body')\nplt.ylabel('Distribution')\nplt.xlim((0,50000))\nplt.tight_layout()\nplt.legend();\n# END SOLUTION",
    "id": "ccae3bbd17a7472584923d1fd81f0c4b",
    "idx": 36,
    "time": "2020-11-13T17:39:15.295Z",
    "type": "execution"
   },
   {
    "code": "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n\nX_train = words_in_texts(some_words, train['email']) # SOLUTION\nY_train = np.array(train['spam']) # SOLUTION\n\nX_train[:5], Y_train[:5]",
    "id": "4228df6326c449d782e8471fb2f787fe",
    "idx": 39,
    "time": "2020-11-13T17:39:15.297Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nX_train.shape == (7513, 5)",
    "id": "16be536580a04248971c0fcb94bb3f0e",
    "idx": 40,
    "time": "2020-11-13T17:39:15.299Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nnp.array_equal(np.unique(X_train), np.array([0, 1])) # X matrix should consist of only 0 or 1",
    "id": "dc0cb916fcc5470885a644448fa6684c",
    "idx": 41,
    "time": "2020-11-13T17:39:15.301Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nnp.array_equal(np.unique(Y_train), np.array([0, 1])) # y vector should consist of only 0 or 1",
    "id": "7b8699ffc3414488a9d374ae3a762231",
    "idx": 42,
    "time": "2020-11-13T17:39:15.303Z",
    "type": "execution"
   },
   {
    "code": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(solver = 'lbfgs') # SOLUTION\nmodel.fit(X_train, Y_train) # SOLUTION\n\ntraining_accuracy = model.score(X_train, Y_train) # SOLUTION\nprint(\"Training Accuracy: \", training_accuracy)",
    "id": "6a1a859678394a819af601759e1b4c0d",
    "idx": 44,
    "time": "2020-11-13T17:39:15.305Z",
    "type": "execution"
   },
   {
    "code": "# TEST\ntraining_accuracy > 0.72",
    "id": "45afd18c3a604fd8825017255e72891e",
    "idx": 45,
    "time": "2020-11-13T17:39:15.307Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_fp = 0 # SOLUTION\nzero_predictor_fn = sum(Y_train == 1) # SOLUTION\nzero_predictor_fp, zero_predictor_fn",
    "id": "30f5741e6f4742119d46340efe2e6a52",
    "idx": 49,
    "time": "2020-11-13T17:39:15.310Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nzero_predictor_fp >= 0",
    "id": "23064baca6924c4c9f2d7f478494c007",
    "idx": 50,
    "time": "2020-11-13T17:39:15.312Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nzero_predictor_fn >= 0",
    "id": "3475b02fb61a47839320a7c9edd5d518",
    "idx": 51,
    "time": "2020-11-13T17:39:15.314Z",
    "type": "execution"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(zero_predictor_fp, 0)",
    "id": "feef0e913db14b6b8101c4489462b487",
    "idx": 52,
    "time": "2020-11-13T17:39:15.316Z",
    "type": "execution"
   },
   {
    "code": "# HIDDEN TEST\nzero_predictor_fn == 1918",
    "id": "8dde97c384214925a9c7f42f58f87aaf",
    "idx": 53,
    "time": "2020-11-13T17:39:15.318Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_acc = np.mean(Y_train == 0) # SOLUTION\nzero_predictor_recall = 0 # SOLUTION\nzero_predictor_acc, zero_predictor_recall",
    "id": "933ef39465ec409e96b3a53f6203baab",
    "idx": 55,
    "time": "2020-11-13T17:39:15.321Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nzero_predictor_acc >= 0",
    "id": "2499a1d760f1441299b055adc8736e68",
    "idx": 56,
    "time": "2020-11-13T17:39:15.322Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nzero_predictor_recall >= 0",
    "id": "2de51ed2ec9f4e11be1000fb204774a3",
    "idx": 57,
    "time": "2020-11-13T17:39:15.324Z",
    "type": "execution"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(zero_predictor_acc, 0.7447091707706642)",
    "id": "ff5d5782535a42019b7eb5a8ec2753dc",
    "idx": 58,
    "time": "2020-11-13T17:39:15.325Z",
    "type": "execution"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(zero_predictor_recall, 0)",
    "id": "f0850a5e5e024d2d9f9bcafe925e1901",
    "idx": 59,
    "time": "2020-11-13T17:39:15.327Z",
    "type": "execution"
   },
   {
    "code": "# BEGIN SOLUTION NO PROMPT\nY_train_hat = model.predict(X_train)\n\nTP = sum((Y_train_hat == Y_train) & (Y_train_hat == 1))\nTN = sum((Y_train_hat == Y_train) & (Y_train_hat == 0))\nFP = sum((Y_train_hat != Y_train) & (Y_train_hat == 1))\nFN = sum((Y_train_hat != Y_train) & (Y_train_hat == 0))\n# END SOLUTION\nlogistic_predictor_precision = TP / (TP + FP) # SOLUTION\nlogistic_predictor_recall = TP / (TP + FN) # SOLUTION\nlogistic_predictor_far = FP / (FP + TN) # SOLUTION",
    "id": "aa340a7e7443411fb115580a71b83b27",
    "idx": 63,
    "time": "2020-11-13T17:39:15.330Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nlogistic_predictor_precision >= 0",
    "id": "2be7e72466a649f1822d8f8458cf3921",
    "idx": 64,
    "time": "2020-11-13T17:39:15.332Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nlogistic_predictor_recall >= 0",
    "id": "70a7e749219e434092993513497dc589",
    "idx": 65,
    "time": "2020-11-13T17:39:15.335Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nlogistic_predictor_far >= 0",
    "id": "c555cae2efe24a11960d966fee18793b",
    "idx": 66,
    "time": "2020-11-13T17:39:15.335Z",
    "type": "execution"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(logistic_predictor_precision, 0.6422287390029325)",
    "id": "84339b96007044c18bb3370123e713d5",
    "idx": 67,
    "time": "2020-11-13T17:39:15.338Z",
    "type": "execution"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(logistic_predictor_recall, 0.11418143899895725)",
    "id": "e9752dbea367428782b9be92a30dfd54",
    "idx": 68,
    "time": "2020-11-13T17:39:15.340Z",
    "type": "execution"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(logistic_predictor_far, 0.021805183199285077)",
    "id": "b7177c97cf0a4893a65e2229d24bddde",
    "idx": 69,
    "time": "2020-11-13T17:39:15.341Z",
    "type": "execution"
   },
   {
    "code": "# Write your description (2-3 sentences) as a comment here:\n# \n#\n#\n\n# Write the code to generate your visualization here:\n# BEGIN SOLUTION\nplt.plot([1, 3, 5]) # This is a dummy plot, not a real example of a solution\n# END SOLUTION",
    "id": "8c0c0ab98ec64e0f843fdaaa8287e1b3",
    "idx": 79,
    "time": "2020-11-13T17:39:15.347Z",
    "type": "execution"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\n# BEGIN SOLUTION\nstaff_words = ['body', 'click', 'please', 'base64', '2002', 'html', 'subscribed',\n               'wrote', 'mortgage', 'align3dcenterfont', 'dear', 'br', 'width10img',\n               'divfont', 'im', 'receive', 'list', 'tags', 'web', 'base64', 'click',\n               'body', 'please', 'money', 'offer', 'receive', 'contact', 'free',\n               'tr', 'removed', 'remove', 'html', 'font', 'form',\n               'credit', 'business', 'div']\n\nX_train_2 = words_in_texts(staff_words, train['email'])\n\nstaff_model = LogisticRegression(solver = 'lbfgs')\nstaff_model.fit(X_train_2, Y_train)\n\nprint('accuracy: ', staff_model.score(X_train_2, Y_train))\n\nY_predict = staff_model.predict_proba(X_train_2)[:, 1]\nfpr, tpr, thresholds = roc_curve(Y_train, Y_predict)\nwith sns.axes_style(\"white\"):\n    plt.plot(fpr, tpr)\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.show()\n# END SOLUTION",
    "id": "8059141c245f48d1843bcdba92a55cd9",
    "idx": 81,
    "time": "2020-11-13T17:39:15.349Z",
    "type": "execution"
   },
   {
    "code": "test_predictions = staff_model.predict(words_in_texts(staff_words, test['email'])) # SOLUTION",
    "id": "b3b715b7bbe440a29afc031436448f68",
    "idx": 83,
    "time": "2020-11-13T17:39:15.351Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nisinstance(test_predictions, np.ndarray) # must be ndarray of predictions",
    "id": "4b8c3b3000f8467d8e92f63713c5a948",
    "idx": 84,
    "time": "2020-11-13T17:39:15.353Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nnp.array_equal(np.unique(test_predictions), np.array([0, 1])) # must be binary labels (0 or 1) and not probabilities",
    "id": "e49cb9eca4884f10bd54709c678f11c4",
    "idx": 85,
    "time": "2020-11-13T17:39:15.355Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nlen(test_predictions) == 1000 # must be the right number of predictions",
    "id": "558f42cfe8c64125afce510c3b7d9647",
    "idx": 86,
    "time": "2020-11-13T17:39:15.357Z",
    "type": "execution"
   },
   {
    "code": "from datetime import datetime\n\n# Assuming that your predictions on the test set are stored in a 1-dimensional array called\n# test_predictions. Feel free to modify this cell as long you create a CSV in the right format.\n\n# Construct and save the submission:\nsubmission_df = pd.DataFrame({\n    \"Id\": test['id'], \n    \"Class\": test_predictions,\n}, columns=['Id', 'Class'])\ntimestamp = datetime.isoformat(datetime.now()).split(\".\")[0]\nsubmission_df.to_csv(\"submission_{}.csv\".format(timestamp), index=False)\n\nprint('Created a CSV file: {}.'.format(\"submission_{}.csv\".format(timestamp)))\nprint('You may now upload this CSV file to Gradescope for scoring.')",
    "id": "951a8f66c9384b52b03fd07762ba6645",
    "idx": 88,
    "time": "2020-11-13T17:39:15.359Z",
    "type": "execution"
   },
   {
    "id": "bf4059a762a047a6a8e4179dc2c11815",
    "time": "2020-11-13T17:39:15.381Z",
    "type": "completion"
   },
   {
    "id": "679de399389b410fbd1bd229389869ba",
    "time": "2020-11-13T17:39:16.314Z",
    "type": "completion"
   },
   {
    "id": "668f75f782c041508f9e0c8f82311ad1",
    "time": "2020-11-13T17:39:17.398Z",
    "type": "completion"
   },
   {
    "id": "68e38b511a2c4f5480d4eda2b0082a11",
    "time": "2020-11-13T17:39:17.402Z",
    "type": "completion"
   },
   {
    "id": "7f4b00c62776443e817cd5a255aa14b9",
    "time": "2020-11-13T17:39:17.451Z",
    "type": "completion"
   },
   {
    "id": "bfb55fdfdfb1456785bb78790aad426b",
    "time": "2020-11-13T17:39:17.502Z",
    "type": "completion"
   },
   {
    "id": "6345c5019a384a618017acbb080996d9",
    "time": "2020-11-13T17:39:17.557Z",
    "type": "completion"
   },
   {
    "id": "ee844f20ed0a41c4b81ff495fe482bdf",
    "time": "2020-11-13T17:39:17.641Z",
    "type": "completion"
   },
   {
    "id": "13a350f12fac4931be17235a1daf0a93",
    "time": "2020-11-13T17:39:17.687Z",
    "type": "completion"
   },
   {
    "id": "a90683e4a73346878a06d732d7101c87",
    "time": "2020-11-13T17:39:17.724Z",
    "type": "completion"
   },
   {
    "id": "7523257e508447369ca710ce27eba7b1",
    "time": "2020-11-13T17:39:17.810Z",
    "type": "completion"
   },
   {
    "id": "81aa3a295d054268acb33351ad567192",
    "time": "2020-11-13T17:39:17.822Z",
    "type": "completion"
   },
   {
    "id": "690ffc0aa5e446949b45a8b4ecd76f85",
    "time": "2020-11-13T17:39:17.854Z",
    "type": "completion"
   },
   {
    "id": "c3fba6032da048efaf5bf9b349cfb4f8",
    "time": "2020-11-13T17:39:17.895Z",
    "type": "completion"
   },
   {
    "id": "c248bceea6bd440c870eb7f942fcf77e",
    "time": "2020-11-13T17:39:17.923Z",
    "type": "completion"
   },
   {
    "id": "3da1bb8528f1420d8e4b01106abb0d1c",
    "time": "2020-11-13T17:39:18.623Z",
    "type": "completion"
   },
   {
    "id": "ccae3bbd17a7472584923d1fd81f0c4b",
    "time": "2020-11-13T17:39:19.061Z",
    "type": "completion"
   },
   {
    "id": "4228df6326c449d782e8471fb2f787fe",
    "time": "2020-11-13T17:39:19.120Z",
    "type": "completion"
   },
   {
    "id": "16be536580a04248971c0fcb94bb3f0e",
    "time": "2020-11-13T17:39:19.127Z",
    "type": "completion"
   },
   {
    "id": "dc0cb916fcc5470885a644448fa6684c",
    "time": "2020-11-13T17:39:19.185Z",
    "type": "completion"
   },
   {
    "id": "7b8699ffc3414488a9d374ae3a762231",
    "time": "2020-11-13T17:39:19.247Z",
    "type": "completion"
   },
   {
    "id": "6a1a859678394a819af601759e1b4c0d",
    "time": "2020-11-13T17:39:19.371Z",
    "type": "completion"
   },
   {
    "id": "45afd18c3a604fd8825017255e72891e",
    "time": "2020-11-13T17:39:19.383Z",
    "type": "completion"
   },
   {
    "id": "30f5741e6f4742119d46340efe2e6a52",
    "time": "2020-11-13T17:39:19.485Z",
    "type": "completion"
   },
   {
    "id": "23064baca6924c4c9f2d7f478494c007",
    "time": "2020-11-13T17:39:19.536Z",
    "type": "completion"
   },
   {
    "id": "3475b02fb61a47839320a7c9edd5d518",
    "time": "2020-11-13T17:39:19.588Z",
    "type": "completion"
   },
   {
    "id": "feef0e913db14b6b8101c4489462b487",
    "time": "2020-11-13T17:39:19.642Z",
    "type": "completion"
   },
   {
    "id": "8dde97c384214925a9c7f42f58f87aaf",
    "time": "2020-11-13T17:39:19.709Z",
    "type": "completion"
   },
   {
    "id": "933ef39465ec409e96b3a53f6203baab",
    "time": "2020-11-13T17:39:19.769Z",
    "type": "completion"
   },
   {
    "id": "2499a1d760f1441299b055adc8736e68",
    "time": "2020-11-13T17:39:19.867Z",
    "type": "completion"
   },
   {
    "id": "2de51ed2ec9f4e11be1000fb204774a3",
    "time": "2020-11-13T17:39:20.000Z",
    "type": "completion"
   },
   {
    "id": "ff5d5782535a42019b7eb5a8ec2753dc",
    "time": "2020-11-13T17:39:20.086Z",
    "type": "completion"
   },
   {
    "id": "f0850a5e5e024d2d9f9bcafe925e1901",
    "time": "2020-11-13T17:39:20.167Z",
    "type": "completion"
   },
   {
    "id": "aa340a7e7443411fb115580a71b83b27",
    "time": "2020-11-13T17:39:20.390Z",
    "type": "completion"
   },
   {
    "id": "2be7e72466a649f1822d8f8458cf3921",
    "time": "2020-11-13T17:39:20.396Z",
    "type": "completion"
   },
   {
    "id": "70a7e749219e434092993513497dc589",
    "time": "2020-11-13T17:39:20.469Z",
    "type": "completion"
   },
   {
    "id": "c555cae2efe24a11960d966fee18793b",
    "time": "2020-11-13T17:39:20.553Z",
    "type": "completion"
   },
   {
    "id": "84339b96007044c18bb3370123e713d5",
    "time": "2020-11-13T17:39:20.650Z",
    "type": "completion"
   },
   {
    "id": "e9752dbea367428782b9be92a30dfd54",
    "time": "2020-11-13T17:39:20.717Z",
    "type": "completion"
   },
   {
    "id": "b7177c97cf0a4893a65e2229d24bddde",
    "time": "2020-11-13T17:39:20.772Z",
    "type": "completion"
   },
   {
    "id": "8c0c0ab98ec64e0f843fdaaa8287e1b3",
    "time": "2020-11-13T17:39:21.057Z",
    "type": "completion"
   },
   {
    "id": "8059141c245f48d1843bcdba92a55cd9",
    "time": "2020-11-13T17:39:22.358Z",
    "type": "completion"
   },
   {
    "id": "b3b715b7bbe440a29afc031436448f68",
    "time": "2020-11-13T17:39:22.422Z",
    "type": "completion"
   },
   {
    "id": "4b8c3b3000f8467d8e92f63713c5a948",
    "time": "2020-11-13T17:39:22.456Z",
    "type": "completion"
   },
   {
    "id": "e49cb9eca4884f10bd54709c678f11c4",
    "time": "2020-11-13T17:39:22.531Z",
    "type": "completion"
   },
   {
    "id": "558f42cfe8c64125afce510c3b7d9647",
    "time": "2020-11-13T17:39:22.633Z",
    "type": "completion"
   },
   {
    "id": "951a8f66c9384b52b03fd07762ba6645",
    "time": "2020-11-13T17:39:22.769Z",
    "type": "completion"
   },
   {
    "code": "sns.distplot(tmp[tmp['spam']==0].length)",
    "id": "7d23973917c7446e89e5254e568f0870",
    "idx": 37,
    "time": "2020-11-13T17:47:19.110Z",
    "type": "execution"
   },
   {
    "id": "7d23973917c7446e89e5254e568f0870",
    "time": "2020-11-13T17:47:19.599Z",
    "type": "completion"
   },
   {
    "code": "sns.distplot(tmp[tmp['spam']==1].length)",
    "id": "3fa95f246e09494289e5530c5b1afc30",
    "idx": 37,
    "time": "2020-11-13T17:47:27.053Z",
    "type": "execution"
   },
   {
    "id": "3fa95f246e09494289e5530c5b1afc30",
    "time": "2020-11-13T17:47:27.538Z",
    "type": "completion"
   },
   {
    "code": "sns.distplot(tmp[tmp['spam']==1].length)\nplt.xlim(0, 50000)",
    "id": "3fa95f246e09494289e5530c5b1afc30",
    "idx": 37,
    "time": "2020-11-13T17:47:41.149Z",
    "type": "execution"
   },
   {
    "id": "3fa95f246e09494289e5530c5b1afc30",
    "time": "2020-11-13T17:47:41.623Z",
    "type": "completion"
   },
   {
    "code": "sns.distplot(tmp[tmp['spam']==0].length)\nplt.xlim(0, 50000)",
    "id": "7d23973917c7446e89e5254e568f0870",
    "idx": 38,
    "time": "2020-11-13T17:47:45.930Z",
    "type": "execution"
   },
   {
    "id": "7d23973917c7446e89e5254e568f0870",
    "time": "2020-11-13T17:47:46.515Z",
    "type": "completion"
   },
   {
    "code": "# BEGIN SOLUTION\ntmp = train.copy()\ntmp['length'] = tmp['email'].str.len()\nplt.figure(figsize=(10, 6))\nsns.distplot(tmp.loc[tmp['spam'] == 0, 'length'],hist=False, label='Ham')\nsns.distplot(tmp.loc[tmp['spam'] == 1, 'length'],hist=False, label='Spam')\nplt.title('Distribution of Email Body Length')\nplt.xlabel('Length of email body')\nplt.ylabel('Distribution')\nplt.xlim((0,50000))\nplt.tight_layout()\nplt.legend();\n# END SOLUTION\nplt.savefig('training_conditional_densities.png')",
    "id": "ccae3bbd17a7472584923d1fd81f0c4b",
    "idx": 36,
    "time": "2020-11-13T17:48:23.568Z",
    "type": "execution"
   },
   {
    "id": "ccae3bbd17a7472584923d1fd81f0c4b",
    "time": "2020-11-13T17:48:24.403Z",
    "type": "completion"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "bf4059a762a047a6a8e4179dc2c11815",
    "idx": 5,
    "time": "2020-11-13T17:50:40.136Z",
    "type": "execution"
   },
   {
    "id": "bf4059a762a047a6a8e4179dc2c11815",
    "time": "2020-11-13T17:50:40.313Z",
    "type": "completion"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "679de399389b410fbd1bd229389869ba",
    "idx": 8,
    "time": "2020-11-13T17:50:40.821Z",
    "type": "execution"
   },
   {
    "id": "679de399389b410fbd1bd229389869ba",
    "time": "2020-11-13T17:50:40.897Z",
    "type": "completion"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "668f75f782c041508f9e0c8f82311ad1",
    "idx": 10,
    "time": "2020-11-13T17:50:41.062Z",
    "type": "execution"
   },
   {
    "code": "# BEGIN SOLUTION\nprint('Before imputation:')\nprint(original_training_data.isnull().sum())\noriginal_training_data = original_training_data.fillna('')\nprint('------------')\nprint('After imputation:')\nprint(original_training_data.isnull().sum())\n# END SOLUTION",
    "id": "68e38b511a2c4f5480d4eda2b0082a11",
    "idx": 12,
    "time": "2020-11-13T17:50:41.287Z",
    "type": "execution"
   },
   {
    "code": "# TEST\noriginal_training_data.isnull().sum().sum() == 0",
    "id": "7f4b00c62776443e817cd5a255aa14b9",
    "idx": 13,
    "time": "2020-11-13T17:50:41.411Z",
    "type": "execution"
   },
   {
    "id": "668f75f782c041508f9e0c8f82311ad1",
    "time": "2020-11-13T17:50:41.553Z",
    "type": "completion"
   },
   {
    "id": "68e38b511a2c4f5480d4eda2b0082a11",
    "time": "2020-11-13T17:50:41.562Z",
    "type": "completion"
   },
   {
    "id": "7f4b00c62776443e817cd5a255aa14b9",
    "time": "2020-11-13T17:50:41.606Z",
    "type": "completion"
   },
   {
    "code": "first_ham = original_training_data.loc[original_training_data['spam'] == 0, 'email'].iloc[0] # SOLUTION\nfirst_spam = original_training_data.loc[original_training_data['spam'] == 1, 'email'].iloc[0] # SOLUTION\nprint(first_ham)\nprint(first_spam)",
    "id": "bfb55fdfdfb1456785bb78790aad426b",
    "idx": 15,
    "time": "2020-11-13T17:50:42.451Z",
    "type": "execution"
   },
   {
    "id": "bfb55fdfdfb1456785bb78790aad426b",
    "time": "2020-11-13T17:50:42.530Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nlen(first_ham) > 0 and first_ham[:0] == ''",
    "id": "6345c5019a384a618017acbb080996d9",
    "idx": 16,
    "time": "2020-11-13T17:50:42.586Z",
    "type": "execution"
   },
   {
    "id": "6345c5019a384a618017acbb080996d9",
    "time": "2020-11-13T17:50:42.656Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nlen(first_spam) > 0 and first_spam[:0] == ''",
    "id": "ee844f20ed0a41c4b81ff495fe482bdf",
    "idx": 17,
    "time": "2020-11-13T17:50:42.774Z",
    "type": "execution"
   },
   {
    "id": "ee844f20ed0a41c4b81ff495fe482bdf",
    "time": "2020-11-13T17:50:42.839Z",
    "type": "completion"
   },
   {
    "code": "# HIDDEN TEST\noriginal_training_data.loc[original_training_data['spam'] == 0, 'email'].iloc[0] in first_ham",
    "id": "13a350f12fac4931be17235a1daf0a93",
    "idx": 18,
    "time": "2020-11-13T17:50:42.995Z",
    "type": "execution"
   },
   {
    "id": "13a350f12fac4931be17235a1daf0a93",
    "time": "2020-11-13T17:50:43.069Z",
    "type": "completion"
   },
   {
    "code": "# HIDDEN TEST\noriginal_training_data.loc[original_training_data['spam'] == 1, 'email'].iloc[0] in first_spam",
    "id": "a90683e4a73346878a06d732d7101c87",
    "idx": 19,
    "time": "2020-11-13T17:50:43.103Z",
    "type": "execution"
   },
   {
    "id": "a90683e4a73346878a06d732d7101c87",
    "time": "2020-11-13T17:50:43.180Z",
    "type": "completion"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "7523257e508447369ca710ce27eba7b1",
    "idx": 23,
    "time": "2020-11-13T17:50:43.719Z",
    "type": "execution"
   },
   {
    "id": "7523257e508447369ca710ce27eba7b1",
    "time": "2020-11-13T17:50:43.793Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = 1 * np.array([texts.str.contains(word) for word in words]).T # SOLUTION\n    return indicator_array",
    "id": "81aa3a295d054268acb33351ad567192",
    "idx": 26,
    "time": "2020-11-13T17:50:44.197Z",
    "type": "execution"
   },
   {
    "id": "81aa3a295d054268acb33351ad567192",
    "time": "2020-11-13T17:50:44.266Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nnp.allclose(words_in_texts(['hello', 'bye', 'world'], \n                           pd.Series(['hello', 'hello worldhello'])),\n            np.array([[1, 0, 0], \n                      [1, 0, 1]]))",
    "id": "690ffc0aa5e446949b45a8b4ecd76f85",
    "idx": 27,
    "time": "2020-11-13T17:50:44.320Z",
    "type": "execution"
   },
   {
    "id": "690ffc0aa5e446949b45a8b4ecd76f85",
    "time": "2020-11-13T17:50:44.392Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nnp.allclose(words_in_texts(['a', 'b', 'c', 'd', 'e', 'f', 'g'], \n                           pd.Series(['a b c d ef g', 'a', 'b', 'c', 'd e f g', 'h', 'a h'])),\n            np.array([[1,1,1,1,1,1,1], \n                      [1,0,0,0,0,0,0],\n                      [0,1,0,0,0,0,0],\n                      [0,0,1,0,0,0,0],\n                      [0,0,0,1,1,1,1],\n                      [0,0,0,0,0,0,0],\n                      [1,0,0,0,0,0,0]]))",
    "id": "c3fba6032da048efaf5bf9b349cfb4f8",
    "idx": 28,
    "time": "2020-11-13T17:50:44.456Z",
    "type": "execution"
   },
   {
    "id": "c3fba6032da048efaf5bf9b349cfb4f8",
    "time": "2020-11-13T17:50:44.532Z",
    "type": "completion"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "c248bceea6bd440c870eb7f942fcf77e",
    "idx": 31,
    "time": "2020-11-13T17:50:44.843Z",
    "type": "execution"
   },
   {
    "id": "c248bceea6bd440c870eb7f942fcf77e",
    "time": "2020-11-13T17:50:44.938Z",
    "type": "completion"
   },
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\n\n# BEGIN SOLUTION\nsome_words = ['opportunity', 'bank', 'receive', 'dear', 'best', 'deal']\nPhi_train = words_in_texts(some_words, train['email'])\n\ndf = pd.DataFrame(data = Phi_train, columns = some_words)\ndf['label'] = train['spam']\n\nplt.figure(figsize=(12,8))\nsns.barplot(x = \"variable\", \n            y = \"value\", \n            hue = \"label\", \n            data = (df\n                    .replace({'label': \n                                {0 : 'Ham', \n                                 1 : 'Spam'}})\n                    .melt('label')\n                    .groupby(['label', 'variable'])\n                    .mean()\n                    .reset_index()))\n\nplt.xlabel('Words')\nplt.ylabel('Proportion of Emails')\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\")\nplt.tight_layout()\nplt.show()\n# END SOLUTION",
    "id": "3da1bb8528f1420d8e4b01106abb0d1c",
    "idx": 33,
    "time": "2020-11-13T17:50:45.085Z",
    "type": "execution"
   },
   {
    "code": "# BEGIN SOLUTION\ntmp = train.copy()\ntmp['length'] = tmp['email'].str.len()\nplt.figure(figsize=(10, 6))\nsns.distplot(tmp.loc[tmp['spam'] == 0, 'length'],hist=False, label='Ham')\nsns.distplot(tmp.loc[tmp['spam'] == 1, 'length'],hist=False, label='Spam')\nplt.title('Distribution of Email Body Length')\nplt.xlabel('Length of email body')\nplt.ylabel('Distribution')\nplt.xlim((0,50000))\nplt.tight_layout()\nplt.legend();\n# END SOLUTION\nplt.savefig('training_conditional_densities.png')",
    "id": "ccae3bbd17a7472584923d1fd81f0c4b",
    "idx": 36,
    "time": "2020-11-13T17:50:45.529Z",
    "type": "execution"
   },
   {
    "id": "3da1bb8528f1420d8e4b01106abb0d1c",
    "time": "2020-11-13T17:50:45.785Z",
    "type": "completion"
   },
   {
    "id": "ccae3bbd17a7472584923d1fd81f0c4b",
    "time": "2020-11-13T17:50:46.397Z",
    "type": "completion"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "5717cb1fad9e4423882ebb7402a960d0",
    "idx": 5,
    "time": "2020-11-13T17:52:54.134Z",
    "type": "execution"
   },
   {
    "id": "5717cb1fad9e4423882ebb7402a960d0",
    "time": "2020-11-13T17:52:54.207Z",
    "type": "completion"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "922a4e60525f4eafb7a67d51618380a8",
    "idx": 8,
    "time": "2020-11-13T17:52:54.451Z",
    "type": "execution"
   },
   {
    "id": "922a4e60525f4eafb7a67d51618380a8",
    "time": "2020-11-13T17:52:54.611Z",
    "type": "completion"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "5b789cd4cf994c438c36c83a11f0883e",
    "idx": 10,
    "time": "2020-11-13T17:52:54.797Z",
    "type": "execution"
   },
   {
    "code": "# BEGIN SOLUTION\nprint('Before imputation:')\nprint(original_training_data.isnull().sum())\noriginal_training_data = original_training_data.fillna('')\nprint('------------')\nprint('After imputation:')\nprint(original_training_data.isnull().sum())\n# END SOLUTION",
    "id": "8cc51a7378104317923b12eb8010193c",
    "idx": 12,
    "time": "2020-11-13T17:52:55.069Z",
    "type": "execution"
   },
   {
    "code": "# TEST\noriginal_training_data.isnull().sum().sum() == 0",
    "id": "fd0fc36dcb3e465fa5de88357798251b",
    "idx": 13,
    "time": "2020-11-13T17:52:55.204Z",
    "type": "execution"
   },
   {
    "id": "5b789cd4cf994c438c36c83a11f0883e",
    "time": "2020-11-13T17:52:55.275Z",
    "type": "completion"
   },
   {
    "id": "8cc51a7378104317923b12eb8010193c",
    "time": "2020-11-13T17:52:55.285Z",
    "type": "completion"
   },
   {
    "id": "fd0fc36dcb3e465fa5de88357798251b",
    "time": "2020-11-13T17:52:55.362Z",
    "type": "completion"
   },
   {
    "code": "first_ham = original_training_data.loc[original_training_data['spam'] == 0, 'email'].iloc[0] # SOLUTION\nfirst_spam = original_training_data.loc[original_training_data['spam'] == 1, 'email'].iloc[0] # SOLUTION\nprint(first_ham)\nprint(first_spam)",
    "id": "ec38cd1676674d79a1f78850b2bdeade",
    "idx": 15,
    "time": "2020-11-13T17:52:55.469Z",
    "type": "execution"
   },
   {
    "id": "ec38cd1676674d79a1f78850b2bdeade",
    "time": "2020-11-13T17:52:55.543Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nlen(first_ham) > 0 and first_ham[:0] == ''",
    "id": "91fb9a6b7c524dd1b4ebaf00adfee1e0",
    "idx": 16,
    "time": "2020-11-13T17:52:55.714Z",
    "type": "execution"
   },
   {
    "id": "91fb9a6b7c524dd1b4ebaf00adfee1e0",
    "time": "2020-11-13T17:52:55.787Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nlen(first_spam) > 0 and first_spam[:0] == ''",
    "id": "bc8e6529a6634c3abc2fbbdeb59cf56a",
    "idx": 17,
    "time": "2020-11-13T17:52:55.830Z",
    "type": "execution"
   },
   {
    "id": "bc8e6529a6634c3abc2fbbdeb59cf56a",
    "time": "2020-11-13T17:52:55.908Z",
    "type": "completion"
   },
   {
    "code": "# HIDDEN TEST\noriginal_training_data.loc[original_training_data['spam'] == 0, 'email'].iloc[0] in first_ham",
    "id": "72db8567d04348308e6661ab83085607",
    "idx": 18,
    "time": "2020-11-13T17:52:55.952Z",
    "type": "execution"
   },
   {
    "id": "72db8567d04348308e6661ab83085607",
    "time": "2020-11-13T17:52:56.024Z",
    "type": "completion"
   },
   {
    "code": "# HIDDEN TEST\noriginal_training_data.loc[original_training_data['spam'] == 1, 'email'].iloc[0] in first_spam",
    "id": "3618a1ff098948808c2c917f942d36aa",
    "idx": 19,
    "time": "2020-11-13T17:52:56.076Z",
    "type": "execution"
   },
   {
    "id": "3618a1ff098948808c2c917f942d36aa",
    "time": "2020-11-13T17:52:56.147Z",
    "type": "completion"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "96c9ac16984747308f833d4c03e9ed53",
    "idx": 23,
    "time": "2020-11-13T17:52:56.678Z",
    "type": "execution"
   },
   {
    "id": "96c9ac16984747308f833d4c03e9ed53",
    "time": "2020-11-13T17:52:56.755Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = 1 * np.array([texts.str.contains(word) for word in words]).T # SOLUTION\n    return indicator_array",
    "id": "06639f97d5a240988a6d7dd1e0b48d8b",
    "idx": 26,
    "time": "2020-11-13T17:52:57.072Z",
    "type": "execution"
   },
   {
    "id": "06639f97d5a240988a6d7dd1e0b48d8b",
    "time": "2020-11-13T17:52:57.145Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nnp.allclose(words_in_texts(['hello', 'bye', 'world'], \n                           pd.Series(['hello', 'hello worldhello'])),\n            np.array([[1, 0, 0], \n                      [1, 0, 1]]))",
    "id": "ffde5bde95224ba58486ad532fb5c28c",
    "idx": 27,
    "time": "2020-11-13T17:52:57.170Z",
    "type": "execution"
   },
   {
    "id": "ffde5bde95224ba58486ad532fb5c28c",
    "time": "2020-11-13T17:52:57.245Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nnp.allclose(words_in_texts(['a', 'b', 'c', 'd', 'e', 'f', 'g'], \n                           pd.Series(['a b c d ef g', 'a', 'b', 'c', 'd e f g', 'h', 'a h'])),\n            np.array([[1,1,1,1,1,1,1], \n                      [1,0,0,0,0,0,0],\n                      [0,1,0,0,0,0,0],\n                      [0,0,1,0,0,0,0],\n                      [0,0,0,1,1,1,1],\n                      [0,0,0,0,0,0,0],\n                      [1,0,0,0,0,0,0]]))",
    "id": "e3e6cf9be8e743fba0049d314831aebf",
    "idx": 28,
    "time": "2020-11-13T17:52:57.405Z",
    "type": "execution"
   },
   {
    "id": "e3e6cf9be8e743fba0049d314831aebf",
    "time": "2020-11-13T17:52:57.482Z",
    "type": "completion"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "6dd5159205814d56b783b665571c9441",
    "idx": 31,
    "time": "2020-11-13T17:52:57.979Z",
    "type": "execution"
   },
   {
    "id": "6dd5159205814d56b783b665571c9441",
    "time": "2020-11-13T17:52:58.072Z",
    "type": "completion"
   },
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\n\n# BEGIN SOLUTION\nsome_words = ['opportunity', 'bank', 'receive', 'dear', 'best', 'deal']\nPhi_train = words_in_texts(some_words, train['email'])\n\ndf = pd.DataFrame(data = Phi_train, columns = some_words)\ndf['label'] = train['spam']\n\nplt.figure(figsize=(12,8))\nsns.barplot(x = \"variable\", \n            y = \"value\", \n            hue = \"label\", \n            data = (df\n                    .replace({'label': \n                                {0 : 'Ham', \n                                 1 : 'Spam'}})\n                    .melt('label')\n                    .groupby(['label', 'variable'])\n                    .mean()\n                    .reset_index()))\n\nplt.xlabel('Words')\nplt.ylabel('Proportion of Emails')\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\")\nplt.tight_layout()\nplt.show()\n# END SOLUTION",
    "id": "cc68f68e069e48788281a1bc9531d83d",
    "idx": 33,
    "time": "2020-11-13T17:52:58.316Z",
    "type": "execution"
   },
   {
    "code": "# BEGIN SOLUTION\ntmp = train.copy()\ntmp['length'] = tmp['email'].str.len()\nplt.figure(figsize=(10, 6))\nsns.distplot(tmp.loc[tmp['spam'] == 0, 'length'],hist=False, label='Ham')\nsns.distplot(tmp.loc[tmp['spam'] == 1, 'length'],hist=False, label='Spam')\nplt.title('Distribution of Email Body Length')\nplt.xlabel('Length of email body')\nplt.ylabel('Distribution')\nplt.xlim((0,50000))\nplt.tight_layout()\nplt.legend();\n# END SOLUTION\nplt.savefig('training_conditional_densities.png')",
    "id": "26273859df904aecb41ec51ef7d9885e",
    "idx": 36,
    "time": "2020-11-13T17:52:58.861Z",
    "type": "execution"
   },
   {
    "id": "cc68f68e069e48788281a1bc9531d83d",
    "time": "2020-11-13T17:52:59.050Z",
    "type": "completion"
   },
   {
    "id": "26273859df904aecb41ec51ef7d9885e",
    "time": "2020-11-13T17:52:59.571Z",
    "type": "completion"
   },
   {
    "code": "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n\nX_train = words_in_texts(some_words, train['email']) # SOLUTION\nY_train = np.array(train['spam']) # SOLUTION\n\nX_train[:5], Y_train[:5]",
    "id": "62fb90ac758448c48db77978df497ae6",
    "idx": 39,
    "time": "2020-11-13T17:53:00.275Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nX_train.shape == (7513, 5)",
    "id": "b365b5d2dcef401a8defa85c6f598d02",
    "idx": 40,
    "time": "2020-11-13T17:53:00.406Z",
    "type": "execution"
   },
   {
    "id": "62fb90ac758448c48db77978df497ae6",
    "time": "2020-11-13T17:53:00.493Z",
    "type": "completion"
   },
   {
    "id": "b365b5d2dcef401a8defa85c6f598d02",
    "time": "2020-11-13T17:53:00.498Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nnp.array_equal(np.unique(X_train), np.array([0, 1])) # X matrix should consist of only 0 or 1",
    "id": "47d34afb59514919ba683fa0c888bde4",
    "idx": 41,
    "time": "2020-11-13T17:53:00.534Z",
    "type": "execution"
   },
   {
    "id": "47d34afb59514919ba683fa0c888bde4",
    "time": "2020-11-13T17:53:00.605Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nnp.array_equal(np.unique(Y_train), np.array([0, 1])) # y vector should consist of only 0 or 1",
    "id": "e8cd7ec14d974ad9b019227069f6145d",
    "idx": 42,
    "time": "2020-11-13T17:53:00.660Z",
    "type": "execution"
   },
   {
    "id": "e8cd7ec14d974ad9b019227069f6145d",
    "time": "2020-11-13T17:53:00.733Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(solver = 'lbfgs') # SOLUTION\nmodel.fit(X_train, Y_train) # SOLUTION\n\ntraining_accuracy = model.score(X_train, Y_train) # SOLUTION\nprint(\"Training Accuracy: \", training_accuracy)",
    "id": "d499255244534699864b5465ce019b5d",
    "idx": 44,
    "time": "2020-11-13T17:53:00.942Z",
    "type": "execution"
   },
   {
    "id": "d499255244534699864b5465ce019b5d",
    "time": "2020-11-13T17:53:01.061Z",
    "type": "completion"
   },
   {
    "code": "# TEST\ntraining_accuracy > 0.72",
    "id": "fef1c6cf1e4a4d3c88f2b4953c55e80d",
    "idx": 45,
    "time": "2020-11-13T17:53:01.501Z",
    "type": "execution"
   },
   {
    "id": "fef1c6cf1e4a4d3c88f2b4953c55e80d",
    "time": "2020-11-13T17:53:01.569Z",
    "type": "completion"
   },
   {
    "code": "zero_predictor_fp = 0 # SOLUTION\nzero_predictor_fn = sum(Y_train == 1) # SOLUTION\nzero_predictor_fp, zero_predictor_fn",
    "id": "0cffaab89bf348f189d092a3bfa1ea4d",
    "idx": 49,
    "time": "2020-11-13T17:53:02.485Z",
    "type": "execution"
   },
   {
    "id": "0cffaab89bf348f189d092a3bfa1ea4d",
    "time": "2020-11-13T17:53:02.576Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nzero_predictor_fp >= 0",
    "id": "564c1eaebae947b69e6800e2ae98ba16",
    "idx": 50,
    "time": "2020-11-13T17:53:02.634Z",
    "type": "execution"
   },
   {
    "id": "564c1eaebae947b69e6800e2ae98ba16",
    "time": "2020-11-13T17:53:02.712Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nzero_predictor_fn >= 0",
    "id": "8a79d709c33749518cf44392623bb119",
    "idx": 51,
    "time": "2020-11-13T17:53:02.760Z",
    "type": "execution"
   },
   {
    "id": "8a79d709c33749518cf44392623bb119",
    "time": "2020-11-13T17:53:02.832Z",
    "type": "completion"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(zero_predictor_fp, 0)",
    "id": "d6ef40aabfde4fd9afc5e0ae8a2f9a56",
    "idx": 52,
    "time": "2020-11-13T17:53:02.881Z",
    "type": "execution"
   },
   {
    "id": "d6ef40aabfde4fd9afc5e0ae8a2f9a56",
    "time": "2020-11-13T17:53:02.953Z",
    "type": "completion"
   },
   {
    "code": "# HIDDEN TEST\nzero_predictor_fn == 1918",
    "id": "dd9b240252164f86b72fb4a1a40682d4",
    "idx": 53,
    "time": "2020-11-13T17:53:03.012Z",
    "type": "execution"
   },
   {
    "id": "dd9b240252164f86b72fb4a1a40682d4",
    "time": "2020-11-13T17:53:03.092Z",
    "type": "completion"
   },
   {
    "code": "zero_predictor_acc = np.mean(Y_train == 0) # SOLUTION\nzero_predictor_recall = 0 # SOLUTION\nzero_predictor_acc, zero_predictor_recall",
    "id": "84771e6a5b2d4591884e110cd14df188",
    "idx": 55,
    "time": "2020-11-13T17:53:03.505Z",
    "type": "execution"
   },
   {
    "id": "84771e6a5b2d4591884e110cd14df188",
    "time": "2020-11-13T17:53:03.572Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nzero_predictor_acc >= 0",
    "id": "060a99ebe6ce4a5086717f109d2e7dca",
    "idx": 56,
    "time": "2020-11-13T17:53:03.631Z",
    "type": "execution"
   },
   {
    "id": "060a99ebe6ce4a5086717f109d2e7dca",
    "time": "2020-11-13T17:53:03.702Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nzero_predictor_recall >= 0",
    "id": "16d18caac2104e4caf93f13a65241938",
    "idx": 57,
    "time": "2020-11-13T17:53:03.762Z",
    "type": "execution"
   },
   {
    "id": "16d18caac2104e4caf93f13a65241938",
    "time": "2020-11-13T17:53:03.831Z",
    "type": "completion"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(zero_predictor_acc, 0.7447091707706642)",
    "id": "be360f140fc546fd8b086891e6614438",
    "idx": 58,
    "time": "2020-11-13T17:53:04.126Z",
    "type": "execution"
   },
   {
    "id": "be360f140fc546fd8b086891e6614438",
    "time": "2020-11-13T17:53:04.196Z",
    "type": "completion"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(zero_predictor_recall, 0)",
    "id": "34130958f5e14ea2aa8627842fa37faf",
    "idx": 59,
    "time": "2020-11-13T17:53:04.243Z",
    "type": "execution"
   },
   {
    "id": "34130958f5e14ea2aa8627842fa37faf",
    "time": "2020-11-13T17:53:04.312Z",
    "type": "completion"
   },
   {
    "code": "# BEGIN SOLUTION NO PROMPT\nY_train_hat = model.predict(X_train)\n\nTP = sum((Y_train_hat == Y_train) & (Y_train_hat == 1))\nTN = sum((Y_train_hat == Y_train) & (Y_train_hat == 0))\nFP = sum((Y_train_hat != Y_train) & (Y_train_hat == 1))\nFN = sum((Y_train_hat != Y_train) & (Y_train_hat == 0))\n# END SOLUTION\nlogistic_predictor_precision = TP / (TP + FP) # SOLUTION\nlogistic_predictor_recall = TP / (TP + FN) # SOLUTION\nlogistic_predictor_far = FP / (FP + TN) # SOLUTION",
    "id": "69a4c98c4a1e45449c52800df7da21d9",
    "idx": 63,
    "time": "2020-11-13T17:53:04.794Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nlogistic_predictor_precision >= 0",
    "id": "4fa2f8b900fa476f8ec08629fe9787aa",
    "idx": 64,
    "time": "2020-11-13T17:53:04.910Z",
    "type": "execution"
   },
   {
    "id": "69a4c98c4a1e45449c52800df7da21d9",
    "time": "2020-11-13T17:53:05.010Z",
    "type": "completion"
   },
   {
    "id": "4fa2f8b900fa476f8ec08629fe9787aa",
    "time": "2020-11-13T17:53:05.020Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nlogistic_predictor_recall >= 0",
    "id": "f169fcb087ce4e1d87d7cada8bfc94a6",
    "idx": 65,
    "time": "2020-11-13T17:53:05.035Z",
    "type": "execution"
   },
   {
    "id": "f169fcb087ce4e1d87d7cada8bfc94a6",
    "time": "2020-11-13T17:53:05.111Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nlogistic_predictor_far >= 0",
    "id": "ce0f25f5620849cc9a33d61b84e5caf6",
    "idx": 66,
    "time": "2020-11-13T17:53:05.173Z",
    "type": "execution"
   },
   {
    "id": "ce0f25f5620849cc9a33d61b84e5caf6",
    "time": "2020-11-13T17:53:05.250Z",
    "type": "completion"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(logistic_predictor_precision, 0.6422287390029325)",
    "id": "2da6368a3815416ba07c4cbfaf0533d5",
    "idx": 67,
    "time": "2020-11-13T17:53:05.299Z",
    "type": "execution"
   },
   {
    "id": "2da6368a3815416ba07c4cbfaf0533d5",
    "time": "2020-11-13T17:53:05.379Z",
    "type": "completion"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(logistic_predictor_recall, 0.11418143899895725)",
    "id": "1f49e01547f844499992699a3f8437d4",
    "idx": 68,
    "time": "2020-11-13T17:53:05.414Z",
    "type": "execution"
   },
   {
    "id": "1f49e01547f844499992699a3f8437d4",
    "time": "2020-11-13T17:53:05.484Z",
    "type": "completion"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(logistic_predictor_far, 0.021805183199285077)",
    "id": "a86939b61fe7402b9bd562eda7adcb8a",
    "idx": 69,
    "time": "2020-11-13T17:53:05.535Z",
    "type": "execution"
   },
   {
    "id": "a86939b61fe7402b9bd562eda7adcb8a",
    "time": "2020-11-13T17:53:05.607Z",
    "type": "completion"
   },
   {
    "code": "# Write your description (2-3 sentences) as a comment here:\n# \n#\n#\n\n# Write the code to generate your visualization here:\n# BEGIN SOLUTION\nplt.plot([1, 3, 5]) # This is a dummy plot, not a real example of a solution\n# END SOLUTION",
    "id": "f9dd9c1872054b3aabcc6cde9965ad16",
    "idx": 79,
    "time": "2020-11-13T17:53:06.802Z",
    "type": "execution"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\n# BEGIN SOLUTION\nstaff_words = ['body', 'click', 'please', 'base64', '2002', 'html', 'subscribed',\n               'wrote', 'mortgage', 'align3dcenterfont', 'dear', 'br', 'width10img',\n               'divfont', 'im', 'receive', 'list', 'tags', 'web', 'base64', 'click',\n               'body', 'please', 'money', 'offer', 'receive', 'contact', 'free',\n               'tr', 'removed', 'remove', 'html', 'font', 'form',\n               'credit', 'business', 'div']\n\nX_train_2 = words_in_texts(staff_words, train['email'])\n\nstaff_model = LogisticRegression(solver = 'lbfgs')\nstaff_model.fit(X_train_2, Y_train)\n\nprint('accuracy: ', staff_model.score(X_train_2, Y_train))\n\nY_predict = staff_model.predict_proba(X_train_2)[:, 1]\nfpr, tpr, thresholds = roc_curve(Y_train, Y_predict)\nwith sns.axes_style(\"white\"):\n    plt.plot(fpr, tpr)\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.show()\n# END SOLUTION",
    "id": "73428c5ed83743b199ed18dc26f18be3",
    "idx": 81,
    "time": "2020-11-13T17:53:07.068Z",
    "type": "execution"
   },
   {
    "id": "f9dd9c1872054b3aabcc6cde9965ad16",
    "time": "2020-11-13T17:53:07.170Z",
    "type": "completion"
   },
   {
    "code": "test_predictions = staff_model.predict(words_in_texts(staff_words, test['email'])) # SOLUTION",
    "id": "665d4320ee5a44fd8e5fc2cc55ecd777",
    "idx": 83,
    "time": "2020-11-13T17:53:07.542Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nisinstance(test_predictions, np.ndarray) # must be ndarray of predictions",
    "id": "0dd28fcc619746e4831ad536f8956532",
    "idx": 84,
    "time": "2020-11-13T17:53:07.669Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nnp.array_equal(np.unique(test_predictions), np.array([0, 1])) # must be binary labels (0 or 1) and not probabilities",
    "id": "6ccaddb5360c45609af4d3b6991ca741",
    "idx": 85,
    "time": "2020-11-13T17:53:07.805Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nlen(test_predictions) == 1000 # must be the right number of predictions",
    "id": "e8c8f77a5758407293ae0b201063880f",
    "idx": 86,
    "time": "2020-11-13T17:53:07.949Z",
    "type": "execution"
   },
   {
    "code": "from datetime import datetime\n\n# Assuming that your predictions on the test set are stored in a 1-dimensional array called\n# test_predictions. Feel free to modify this cell as long you create a CSV in the right format.\n\n# Construct and save the submission:\nsubmission_df = pd.DataFrame({\n    \"Id\": test['id'], \n    \"Class\": test_predictions,\n}, columns=['Id', 'Class'])\ntimestamp = datetime.isoformat(datetime.now()).split(\".\")[0]\nsubmission_df.to_csv(\"submission_{}.csv\".format(timestamp), index=False)\n\nprint('Created a CSV file: {}.'.format(\"submission_{}.csv\".format(timestamp)))\nprint('You may now upload this CSV file to Gradescope for scoring.')",
    "id": "aa5bacff8532404a8471d14006215349",
    "idx": 88,
    "time": "2020-11-13T17:53:08.231Z",
    "type": "execution"
   },
   {
    "id": "73428c5ed83743b199ed18dc26f18be3",
    "time": "2020-11-13T17:53:08.462Z",
    "type": "completion"
   },
   {
    "id": "665d4320ee5a44fd8e5fc2cc55ecd777",
    "time": "2020-11-13T17:53:08.523Z",
    "type": "completion"
   },
   {
    "id": "0dd28fcc619746e4831ad536f8956532",
    "time": "2020-11-13T17:53:08.540Z",
    "type": "completion"
   },
   {
    "id": "6ccaddb5360c45609af4d3b6991ca741",
    "time": "2020-11-13T17:53:08.558Z",
    "type": "completion"
   },
   {
    "id": "e8c8f77a5758407293ae0b201063880f",
    "time": "2020-11-13T17:53:08.585Z",
    "type": "completion"
   },
   {
    "id": "aa5bacff8532404a8471d14006215349",
    "time": "2020-11-13T17:53:08.632Z",
    "type": "completion"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
